{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9257f2",
   "metadata": {},
   "source": [
    "# Generate the 3 tank dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d1420",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from scipy.integrate import odeint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b211760",
   "metadata": {},
   "source": [
    "### Simulation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeTankSimulation:\n",
    "    \"\"\"Simulates the three tank system.\n",
    "    The system is simulated using the scipy odeint function.\n",
    "    \"\"\"\n",
    "    def __init__(self, tank_1_lvl=0, tank_2_lvl=0, tank_3_lvl=0, seed=42):\n",
    "        self.tank_levels = np.array([tank_1_lvl, tank_2_lvl, tank_3_lvl])\n",
    "        self.seed = seed\n",
    "        self.state_df = pd.DataFrame(columns=[\"q1\", \"q3\", \"kv1\", \"kv2\", \"kv3\", \"duration\"])\n",
    "\n",
    "    def add_state(self, q1: float, q3: float, kv1: float, kv2: float, kv3: float, duration: int, name=None) -> None:\n",
    "        \"\"\"Add a state to the state dataframe.\n",
    "        A state consists of specific settings to the system's parameters.\n",
    "        Args:\n",
    "            q1 (float): inflow tank 1\n",
    "            q3 (float): inflow tank 3\n",
    "            kv1 (float): coefficient of the valve between tank 1 and 2\n",
    "            kv2 (float): coefficient of the valve between tank 2 and 3\n",
    "            kv3 (float): coefficient of the outgoing valve on tank 3\n",
    "            duration (int): number of time steps of the state\n",
    "            name (string): the name of the state\n",
    "        \"\"\"\n",
    "        if name is not None:\n",
    "            self.state_df.loc[name] = [q1, q3, kv1, kv2, kv3, duration]\n",
    "        else:\n",
    "            self.state_df.append(dict(q1=q1, q3=q3, kv1=kv1, kv2=kv2, kv3=kv3, duration=duration),\n",
    "                                 ignore_index=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _system_dynamics_function(x, t, q1, q3, kv1, kv2, kv3):\n",
    "        # ensure non-negative tank levels\n",
    "        x1, x2, x3 = x * (x > 0)\n",
    "        # ODE\n",
    "        dh1_dt = q1 - kv1 * np.sign(x1 - x2) * np.sqrt(np.abs(x1 - x2))\n",
    "        dh2_dt = kv1 * np.sign(x1 - x2) * np.sqrt(np.abs(x1 - x2)) \\\n",
    "                 - kv2 * np.sign(x2 - x3) * np.sqrt(np.abs(x2 - x3))\n",
    "        dh3_dt = q3 + kv2 * np.sign(x2 - x3) * np.sqrt(np.abs(x2 - x3)) - kv3 * np.sqrt(x3)\n",
    "\n",
    "        return dh1_dt, dh2_dt, dh3_dt\n",
    "\n",
    "    def _compute_section(self, duration: int = 10, x0: np.array = np.array([30, 10, 50]),\n",
    "                         kv1: float = 1, kv2: float = 1, kv3: float = 1,\n",
    "                         q1: float = 1, q3: float = 1):\n",
    "        t = np.array(range(duration))\n",
    "        y = odeint(self._system_dynamics_function, x0, t, (q1, q3, kv1, kv2, kv3))\n",
    "        # non-negativity\n",
    "        y = y * (y > 0)\n",
    "        y_stop = y[-1, :]\n",
    "        return y, y_stop\n",
    "\n",
    "    @staticmethod\n",
    "    def _duplicate_row(row, factor):\n",
    "        return pd.concat([row.copy()] * factor, axis = 1)\n",
    "\n",
    "    def _configuration_seq(self, cycle: list, nb_of_cycles: int,\n",
    "                           sd_q: float, sd_kv: float, sd_dur: float,\n",
    "                           leaky: bool, periodic_inflow: bool) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"generates configuration dataframes\n",
    "        The configuration dataframe describes the state at every time step.\n",
    "        Outputs original state configuration and configuration with noise.\n",
    "        \"\"\"\n",
    "        # generate cycle of states\n",
    "        seq = list()\n",
    "        for i in range(nb_of_cycles):\n",
    "            for state in cycle:\n",
    "                if type(state) is str:\n",
    "                    seq.append(self.state_df.loc[state])\n",
    "                else:\n",
    "                    seq.append((self.state_df.iloc[state, :]))\n",
    "        seq_df = pd.concat(seq, axis=1).T.astype({\"duration\": int})\n",
    "        seq_len = seq_df.shape[0]\n",
    "\n",
    "        # add periodic inflow\n",
    "        if periodic_inflow:\n",
    "            amplitude = 0.5 * seq_df[\"q1\"].max()\n",
    "            wave = amplitude * np.cos(np.linspace(np.pi, 5*np.pi, 2000))\n",
    "\n",
    "            q1_mask = seq_df[\"q1\"] > 0\n",
    "            q3_mask = seq_df[\"q3\"] > 0\n",
    "            \n",
    "            seq_df.loc[q1_mask, \"q1\"] += wave[:q1_mask.sum()]\n",
    "            seq_df.loc[q3_mask, \"q3\"] += wave[:q3_mask.sum()]\n",
    "\n",
    "        # add noise\n",
    "        np.random.seed(self.seed)\n",
    "        seq_df_noise = seq_df.copy()\n",
    "        if sd_q is not None:\n",
    "            q_noise = np.random.normal(0, sd_q, 2 * seq_len)\n",
    "            seq_df_noise[\"q1\"] = seq_df[\"q1\"] + q_noise[:seq_len]\n",
    "            seq_df_noise[\"q3\"] = seq_df[\"q3\"] + q_noise[seq_len:]\n",
    "            if not leaky:\n",
    "                seq_df_noise[\"q1\"].where(seq_df[\"q1\"] > 0, other=0, inplace=True)  # no leaky inflow\n",
    "                seq_df_noise[\"q3\"].where(seq_df[\"q3\"] > 0, other=0, inplace=True)  # (set back to 0 if no inflow)\n",
    "        if sd_kv is not None:\n",
    "            kv_noise = np.random.normal(0, sd_kv, 3 * seq_len)\n",
    "            seq_df_noise[\"kv1\"] = seq_df[\"kv1\"] + kv_noise[:seq_len]\n",
    "            seq_df_noise[\"kv2\"] = seq_df[\"kv2\"] + kv_noise[seq_len:2*seq_len]\n",
    "            seq_df_noise[\"kv3\"] = seq_df[\"kv3\"] + kv_noise[2*seq_len:]\n",
    "            if not leaky:\n",
    "                seq_df_noise[\"kv1\"].where(seq_df[\"kv1\"] > 0, other=0, inplace=True)  # no leaky valve\n",
    "                seq_df_noise[\"kv2\"].where(seq_df[\"kv2\"] > 0, other=0, inplace=True)\n",
    "                seq_df_noise[\"kv3\"].where(seq_df[\"kv3\"] > 0, other=0, inplace=True)\n",
    "        if sd_dur is not None:\n",
    "            dur_noise = np.random.normal(0, sd_dur, seq_len)\n",
    "            seq_df_noise[\"duration\"] = round(seq_df[\"duration\"] + dur_noise).astype(int)\n",
    "        # no negative inflow etc.\n",
    "        seq_df = seq_df.where(seq_df >= 0, 0)\n",
    "        seq_df_noise = seq_df_noise.where(seq_df_noise >= 0, 0) \n",
    "\n",
    "        return seq_df, seq_df_noise\n",
    "\n",
    "    @staticmethod\n",
    "    def _export_config(seq_df, seq_df_noise, export_path):\n",
    "        \"\"\"exports state configuration dataframe\n",
    "        Transforms the dataframe so that the state at every time step is exported.\n",
    "        \"\"\"\n",
    "        seq0 = list()\n",
    "        seq0_noise = list()\n",
    "        for (_, row), (_, row_noise) in zip(seq_df.iterrows(), seq_df_noise.iterrows()):\n",
    "            duration = int(row_noise.duration)  # actual duration\n",
    "            seq0 += [row] * duration\n",
    "            seq0_noise += [row_noise] * duration\n",
    "        seq0_df = pd.concat(seq0_noise, axis=1).T\n",
    "        seq0_df.to_csv(f\"{export_path[:-4]}_config.csv\", index=False)\n",
    "\n",
    "    def simulate(self, cycle: list, nb_of_cycles: int = 10,\n",
    "                 sd_q: float = None, sd_kv: float = None, sd_dur: float = None, sd_white_noise: float = None, \n",
    "                 leaky: bool = False, periodic_inflow = False,\n",
    "                 export_path: str = None) -> np.array:\n",
    "        \"\"\"Simulates the dynamics in the three-tank system\n",
    "        Args:\n",
    "            cycle (list): sequence of states that compose a typical cycle.\n",
    "                          Either list of integers or list of state names.\n",
    "            nb_of_cycles (int): number of successive cycles to simulate\n",
    "            sd_q (float): if set, white noise with this standard deviation is added to the inflow\n",
    "            sd_kv (float): if set, white noise with this standard deviation is added to the valve coefficients\n",
    "            sd_dur (float): if set, white noise with this standard deviation is added to the duration\n",
    "            leaky (bool): if true, add noise on closed valves or stopped inflow\n",
    "            periodic_inflow (bool): if true, add periodic variation to the inflow\n",
    "            export_path (str): if set, save simulation data at export path\n",
    "        \"\"\"\n",
    "        seq_denoised, seq = self._configuration_seq(cycle, nb_of_cycles, sd_q, sd_kv, sd_dur, leaky, periodic_inflow)\n",
    "\n",
    "        y_ls = []\n",
    "        y_stop = self.tank_levels\n",
    "        for config in tqdm(seq.itertuples(), total=len(seq)):\n",
    "            y, y_stop = self._compute_section(duration=config.duration, x0=y_stop,\n",
    "                                            kv1=config.kv1, kv2=config.kv2, kv3=config.kv3,\n",
    "                                            q1=config.q1, q3=config.q3)\n",
    "            y_ls.append(y)\n",
    "        y_out = np.concatenate(y_ls)\n",
    "\n",
    "        if sd_white_noise is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            y_out += np.random.normal(0, sd_white_noise, y_out.shape)\n",
    "\n",
    "        if export_path is not None:\n",
    "            y_df = pd.DataFrame(y_out, columns=['h1', 'h2', 'h3'])\n",
    "            y_df.to_csv(export_path, index=False)\n",
    "            self._export_config(seq_denoised, seq, export_path)\n",
    "\n",
    "        return y_out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbad7e75",
   "metadata": {},
   "source": [
    "### Plot the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da09bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f53b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simulation(data: np.array, interval=None, title=None, export_path=None, height=None, width=None):\n",
    "    \n",
    "    def add_trace_to_figure(fig, signal_data, signal_name):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.array(range(signal_data.shape[0])),\n",
    "                y=signal_data,\n",
    "                name=signal_name,\n",
    "                mode=\"lines\",\n",
    "                opacity=1\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "\n",
    "    if interval is not None:\n",
    "        data = data[interval[0]:interval[1], :]\n",
    "\n",
    "    # signal_names = [r'$h_1$', r'$h_2$', r'$h_3$']\n",
    "    signal_names = ['h1', 'h2', 'h3']\n",
    "    for signal_data, signal_name in zip(data.T, signal_names):\n",
    "        add_trace_to_figure(fig, signal_data, signal_name)\n",
    "\n",
    "    fig.update_xaxes(title_text='Time Step')\n",
    "    fig.update_yaxes(title_text='Water Level')\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        font=dict(family=\"Serif\", size=18),\n",
    "        margin=dict(l=5, t=50, b=5, r=5),\n",
    "        height=height,\n",
    "        width=width\n",
    "    )\n",
    "\n",
    "    if export_path is not None:\n",
    "        pio.write_image(fig, export_path)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ef54ab",
   "metadata": {},
   "source": [
    "## Generate 3 Tank Systems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd088fe3",
   "metadata": {},
   "source": [
    "- there are 3 tanks\n",
    "- there are 4 system states, each with a fixed duration of 50\n",
    "    1. fill tank 1 (q1)\n",
    "    2. mix tanks 1 and 2 (v12)\n",
    "    3. mix tanks 2 and 3 (v23)\n",
    "    4. empty tank 3 (v3)\n",
    "    \n",
    "- then there are two additional states that are not part of the first dataset to train on\n",
    "\n",
    "    5. nothing happens (rest)\n",
    "    6. fill tank 1 while emptying tank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93156be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tank_1_lvl=7\n",
    "tank_2_lvl=3\n",
    "tank_3_lvl=0\n",
    "q = 0.1\n",
    "kv = 0.1\n",
    "duration = 50\n",
    "\n",
    "system = ThreeTankSimulation(tank_1_lvl=tank_1_lvl, tank_2_lvl=tank_2_lvl, tank_3_lvl=tank_3_lvl)\n",
    "system.add_state(q1=q, q3=0, kv1=0,  kv2=0,  kv3=0,  duration=duration, name=\"q1\")\n",
    "system.add_state(q1=0, q3=0, kv1=kv, kv2=0,  kv3=0,  duration=duration, name=\"v12\")\n",
    "system.add_state(q1=0, q3=0, kv1=0,  kv2=kv, kv3=0,  duration=duration, name=\"v23\")\n",
    "system.add_state(q1=0, q3=0, kv1=0,  kv2=0,  kv3=kv, duration=duration, name=\"v3\")\n",
    "system.add_state(q1=0, q3=0, kv1=0,  kv2=0,  kv3=0,  duration=duration, name=\"rest\")\n",
    "system.add_state(q1=q, q3=0, kv1=0,  kv2=0,  kv3=kv, duration=duration, name=\"q1+v3\")\n",
    "system.add_state(q1=0, q3=0, kv1=kv, kv2=kv, kv3=0,  duration=duration, name=\"v12+v23\")\n",
    "system.add_state(q1=0, q3=q, kv1=0,  kv2=0,  kv3=0,  duration=duration, name=\"q3\")\n",
    "\n",
    "# similar system with different initial conditions\n",
    "c = 1.5\n",
    "system2 = ThreeTankSimulation(tank_1_lvl=c*tank_1_lvl, tank_2_lvl=c*tank_2_lvl, tank_3_lvl=0)\n",
    "system2.add_state(q1=c*q, q3=0, kv1=0,    kv2=0,    kv3=0,    duration=duration, name=\"q1\")\n",
    "system2.add_state(q1=0,   q3=0, kv1=c*kv, kv2=0,    kv3=0,    duration=duration, name=\"v12\")\n",
    "system2.add_state(q1=0,   q3=0, kv1=0,    kv2=c*kv, kv3=0,    duration=duration, name=\"v23\")\n",
    "system2.add_state(q1=0,   q3=0, kv1=0,    kv2=0,    kv3=c*kv, duration=duration, name=\"v3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aefe72b",
   "metadata": {},
   "source": [
    "## Generate Different Scenarios\n",
    "- in every filling phase, the inflow varies, resulting in a diverse but physically feasible 3 tank dataset\n",
    "- to be more realistic, some noise is added to the simulation\n",
    "- the standard scenario: fill T1 -> mix T1 & T2 -> mix T2 & T3 -> empty T3\n",
    "    - with different initial tank level\n",
    "    - with varying amount of inflow variation\n",
    "    - with varying duration of each phase\n",
    "- other scenarios:\n",
    "    - fill T1 & empty T3 -> mix T1 & T2 -> mix T2 & T3\n",
    "    - fill T1 & empty T3 -> rest -> mix T1 & T2 -> mix T2 & T3\n",
    "    - fill T1 & fill T3 -> mix T1 & T2 -> mix T2 & T3 -> empty T3\n",
    "    - fill T1 -> mix T1 & T2 & T3 -> empty T3\n",
    "- furthermore, a scenario with faulty sensors is added later in the DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "513bfa71",
   "metadata": {},
   "source": [
    "### Standard Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8324c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_noise = 0.5\n",
    "sd_q = 0.05  # for one scenario, we add noise on the inflow\n",
    "sd_dur = duration * 0.1  # for one scenario, we add noise on the duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"start standard simulation\")\n",
    "y1 = system.simulate(cycle=[\"q1\", \"v12\", \"v23\", \"q1\", \"v12\", \"v23\", \"v3\"],\n",
    "                    nb_of_cycles=1000,\n",
    "                    sd_q=None, sd_kv=None, sd_dur=None, sd_white_noise=sd_noise,\n",
    "                    periodic_inflow=True,\n",
    "                    export_path=\"data/processed/simulation_standard.csv\"\n",
    "                    )\n",
    "plot_simulation(y1, title=\"Standard Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation(y1, interval=[0,1000], title='Standard Simulation', \n",
    "                export_path='visualizations/simulation_standard.pdf', height=400, width=800)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6349c20d",
   "metadata": {},
   "source": [
    "### Simulations with Different Settings, but the Same Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start scale simulation\")\n",
    "y12 = system2.simulate(cycle=[\"q1\", \"v12\", \"v23\", \"q1\", \"v12\", \"v23\", \"v3\"],\n",
    "                    nb_of_cycles=1000,\n",
    "                    sd_q=None, sd_kv=None, sd_dur=None, sd_white_noise=sd_noise,\n",
    "                    periodic_inflow=True,\n",
    "                    export_path=\"data/processed/simulation_scale.csv\"\n",
    "                    )\n",
    "# plot_simulation(y12, title=\"Similar System with Different Initial Conditions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf2d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start duration simulation\")\n",
    "y2 = system.simulate(cycle=[\"q1\", \"v12\", \"v23\", \"q1\", \"v12\", \"v23\", \"v3\"],\n",
    "                    nb_of_cycles=1000,\n",
    "                    sd_q=None, sd_kv=None, sd_dur=sd_dur, sd_white_noise=sd_noise,\n",
    "                    periodic_inflow=True,\n",
    "                    export_path=\"data/processed/simulation_duration.csv\"\n",
    "                    )\n",
    "# plot_simulation(y2, title=\"Standard Dataset with Variation on Phase Duration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d37b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start noise simulation\")\n",
    "y3 = system.simulate(cycle=[\"q1\", \"v12\", \"v23\", \"q1\", \"v12\", \"v23\", \"v3\"],\n",
    "                    nb_of_cycles=1000,\n",
    "                    sd_q=None, sd_kv=None, sd_dur=None, sd_white_noise=sd_noise * 3,\n",
    "                    periodic_inflow=True,\n",
    "                    export_path=\"data/processed/simulation_noise.csv\"\n",
    "                    )\n",
    "# plot_simulation(y3, title=\"Standard Dataset with more Noise\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad583b61",
   "metadata": {},
   "source": [
    "### Simulations with same Settings, but Different Cycle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start switch simulation\")\n",
    "y4 = system.simulate(cycle=[\"q1\", \"v23\", \"v12\", \"q1\", \"v12\", \"v23\", \"v3\"],\n",
    "                    nb_of_cycles=1000,\n",
    "                    sd_q=None, sd_kv=None, sd_dur=None, sd_white_noise=sd_noise,\n",
    "                    periodic_inflow=True,\n",
    "                    export_path=\"data/processed/simulation_switch.csv\"\n",
    "                    )\n",
    "# plot_simulation(y4, title=\"Switch Order of Mixing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start q1+v3 simulation\")\n",
    "y41 = system.simulate(cycle=[\"v12\", \"v23\", \"q1\", \"v12\", \"v23\", \"q1+v3\"],\n",
    "                    nb_of_cycles=1000,\n",
    "                    sd_q=None, sd_kv=None, sd_dur=None, sd_white_noise=sd_noise,\n",
    "                    periodic_inflow=True,\n",
    "                    export_path=\"data/processed/simulation_q1+v3.csv\"\n",
    "                    )\n",
    "# plot_simulation(y41, title=\"Fill Tank 1 while Emptying Tank 3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b54b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start q1+v3+rest simulation\")\n",
    "y42 = system.simulate(cycle=[\"v12\", \"v23\", \"q1\", \"v12\", \"v23\", \"q1+v3\", \"rest\"],\n",
    "                    nb_of_cycles=1000,\n",
    "                    sd_q=None, sd_kv=None, sd_dur=None, sd_white_noise=sd_noise,\n",
    "                    periodic_inflow=True,\n",
    "                    export_path=\"data/processed/simulation_q1+v3+rest.csv\"\n",
    "                    )\n",
    "# plot_simulation(y42, title=\"Fill Tank 1 while Emptying Tank 3, then Rest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start v12+v23 simulation\")\n",
    "y43 = system.simulate(cycle=[\"q1\", \"v12+v23\", \"q1\", \"v12\", \"v23\", \"v3\"],\n",
    "                    nb_of_cycles=1000,\n",
    "                    sd_q=None, sd_kv=None, sd_dur=None, sd_white_noise=sd_noise,\n",
    "                    periodic_inflow=True,\n",
    "                    export_path=\"data/processed/simulation_v12+v23.csv\"\n",
    "                    )\n",
    "# plot_simulation(y43, title=\"Mix Tank 1, 2 and 3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a735a2",
   "metadata": {},
   "source": [
    "## Build DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, Subset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeTankDataset(Dataset):\n",
    "    \"\"\"Three tank dataset\n",
    "    A sample consists of a random time window + consecutive time window\n",
    "    Args:\n",
    "        file (str): path to csv file containing the data\n",
    "        input_len (int): length of input sequence\n",
    "        pred_len (int): length of prediction sequence\n",
    "        nb_of_samples (int): number of samples to draw\n",
    "        ordered_samples (bool): if true, samples are arranged in order of time\n",
    "        faulty_input (bool): if true, input sequence is faulty\n",
    "        seed (int): random seed\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 file,\n",
    "                 input_len=250,  # should contain at least 4 phases (one standard cycle)\n",
    "                 pred_len=50,\n",
    "                 nb_of_samples=1000,\n",
    "                 ordered_samples=True,\n",
    "                 faulty_input=False,\n",
    "                 seed=42\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        # read data\n",
    "        self.X = pd.read_csv(file)\n",
    "\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "        self.phase_len = 50  # defined in simulation as duration of one phase\n",
    "        self.nb_of_samples = nb_of_samples\n",
    "        self.nb_of_features = self.X.shape[1]\n",
    "\n",
    "        self.ordered_samples = ordered_samples\n",
    "        self.faulty_input = faulty_input\n",
    "        self.sample_idxs = self._create_samples(seed)\n",
    "        self.fault_mask = self._create_faults(seed)\n",
    "\n",
    "    def _create_samples(self, seed):\n",
    "        \"\"\"Create array of random start numbers\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        start_idxs = np.random.randint(0, self.X.shape[0] - self.input_len - self.pred_len, self.nb_of_samples)\n",
    "        if self.ordered_samples:  # for now important due to train/test split in datamodule\n",
    "            start_idxs = np.sort(start_idxs)\n",
    "        return start_idxs\n",
    "    \n",
    "    def _create_faults(self, seed):\n",
    "        \"\"\"Create a mask that simulates faulty sensors\"\"\"\n",
    "        fault_mask = np.ones((self.nb_of_samples, self.input_len, self.nb_of_features), dtype=np.float32)\n",
    "        if self.faulty_input:\n",
    "            np.random.seed(seed)\n",
    "            for i in range(self.nb_of_samples):\n",
    "                # choose a random sensor and a random position in the sequence\n",
    "                sensor = np.random.randint(0, self.nb_of_features)\n",
    "                # either add a point anomaly or simulate a dead sensor\n",
    "                if np.random.rand() < 0.5:\n",
    "                    pos = np.random.randint(0, self.input_len)\n",
    "                    fault_mask[i, pos, sensor] = np.random.rand() * 8 + 2  # random value between 2 and 10\n",
    "                else:\n",
    "                    # make sure the fault is not at the end of the sequence. The last {phase_len} steps should not be faulty\n",
    "                    pos = np.random.randint(0, self.input_len - self.phase_len - 1)\n",
    "                    # choose a random number of consecutive timesteps to be faulty\n",
    "                    # no longer than a phase and no longer than the remaining sequence\n",
    "                    nb_of_steps = np.random.randint(1, min(self.phase_len, self.input_len - self.phase_len - pos))\n",
    "                    fault_mask[i, pos:pos+nb_of_steps, sensor] = 0\n",
    "        return fault_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Size of dataset\"\"\"\n",
    "        return self.nb_of_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get one sample\n",
    "        Simple setup: always yield two samples, x1(t) and concurrent sample x2(t+input_len) (without configurations).\n",
    "        Note that the model can effectively see x2 via a different x1 if dataloader is not chronological.\n",
    "        \"\"\"\n",
    "        start_idx = self.sample_idxs[index]\n",
    "        x1 = self.X.iloc[start_idx: start_idx + self.input_len].to_numpy(dtype=np.float32)\n",
    "        x2 = self.X.iloc[start_idx + self.input_len: start_idx + self.input_len + self.pred_len].to_numpy(dtype=np.float32)\n",
    "        if self.faulty_input:\n",
    "            # element-wise multiplication of input with fault mask\n",
    "            x1 = x1 * self.fault_mask[index]\n",
    "        return x1, x2\n",
    "    \n",
    "\n",
    "class ThreeTankDataModule(pl.LightningDataModule):\n",
    "    \"\"\"Data module for three tank dataset\n",
    "    Args:\n",
    "        eval_ood (bool): if true, evaluate on out-of-distribution data\n",
    "        batch_size (int): batch size\n",
    "        num_workers (int): number of workers for dataloader\n",
    "        pin_memory (bool): pin memory for dataloader\n",
    "        train_split (float): fraction of data used for training\n",
    "        val_split (float): fraction of data used for validation\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 eval_ood=True,\n",
    "                 batch_size=64, num_workers=8, pin_memory=False,\n",
    "                 train_split=0.5, val_split=0.25):\n",
    "        super(ThreeTankDataModule, self).__init__()\n",
    "\n",
    "        self.scenarios = [\n",
    "            \"standard\",\n",
    "            \"fault\",\n",
    "            \"noise\",\n",
    "            \"duration\",\n",
    "            \"scale\",\n",
    "            \"switch\",\n",
    "            \"q1+v3\",\n",
    "            \"q1+v3+rest\",\n",
    "            \"v12+v23\"\n",
    "        ]\n",
    "        self.eval_ood = eval_ood\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "\n",
    "        self.train_split = train_split\n",
    "        self.val_split = val_split\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "    def setup(self, stage=None) -> None:\n",
    "        # standard training set to train on\n",
    "        ds_std = ThreeTankDataset(\n",
    "            \"data/processed/simulation_standard.csv\", \n",
    "            nb_of_samples=1000\n",
    "            )\n",
    "        # [train | val | test] for standard training set  TODO purge\n",
    "        val_start_idx = int(len(ds_std) * self.train_split)\n",
    "        test_start_idx = int(len(ds_std) * (self.train_split + self.val_split))\n",
    "\n",
    "        self.ds_std_train = Subset(ds_std, range(val_start_idx))\n",
    "        self.ds_std_val = Subset(ds_std, range(val_start_idx, test_start_idx))\n",
    "        self.ds_std_test = Subset(ds_std, range(test_start_idx, len(ds_std)))   \n",
    "\n",
    "        # list of ood datasets to validate model on\n",
    "        self.ds_ood_list = [\n",
    "            ThreeTankDataset(\n",
    "                \"data/processed/simulation_standard.csv\",\n",
    "                nb_of_samples=100,\n",
    "                ordered_samples=True,\n",
    "                faulty_input=True,  # simulate faulty sensors\n",
    "                seed=1234  # sample from training dataset but use different seed to avoid overfitting\n",
    "                )\n",
    "        ]\n",
    "        self.ds_ood_list += [\n",
    "            ThreeTankDataset(\n",
    "                f\"data/processed/simulation_{scenario}.csv\", \n",
    "                nb_of_samples=100,\n",
    "                )\n",
    "            for scenario in self.scenarios[2:]\n",
    "        ]\n",
    "        \n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        # [batch_size, seq_len, features], [batch_size, features]\n",
    "        return DataLoader(\n",
    "            self.ds_std_train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        dl_std = DataLoader(\n",
    "            self.ds_std_val,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory\n",
    "            )\n",
    "        if not self.eval_ood:\n",
    "            dl_ood_list = []\n",
    "        else:\n",
    "            dl_ood_list = [\n",
    "                DataLoader(\n",
    "                Subset(ds, range(int(self.train_split * len(ds)), int((self.train_split + self.val_split) * len(ds)))),\n",
    "                batch_size=self.batch_size,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=self.pin_memory\n",
    "                )\n",
    "                for ds in self.ds_ood_list\n",
    "            ]\n",
    "        return [dl_std] + dl_ood_list\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        dl_std = DataLoader(\n",
    "            self.ds_std_test,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory\n",
    "            )\n",
    "        if not self.eval_ood:\n",
    "            dl_ood_list = []\n",
    "        else:\n",
    "            dl_ood_list = [\n",
    "                DataLoader(\n",
    "                Subset(ds, range(int((self.train_split + self.val_split) * len(ds)), len(ds))),\n",
    "                batch_size=self.batch_size,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=self.pin_memory\n",
    "                )\n",
    "                for ds in self.ds_ood_list\n",
    "            ]\n",
    "        return [dl_std] + dl_ood_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ThreeTankDataModule()\n",
    "dm.setup()\n",
    "x1, x2 = dm.ds_std_train[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5893620",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dm.train_dataloader()\n",
    "next(iter(dl))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(ds, index):\n",
    "    # (x1, s1), (x2, s2) = ds[index]\n",
    "    x1, x2 = ds[index]\n",
    "\n",
    "    x = np.concatenate((x1, x2))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for sig, name in zip([x[:, 0], x[:, 1], x[:, 2]],\n",
    "                         ['h1', 'h2', 'h3']):\n",
    "        fig.add_trace(go.Scatter(x=np.array(range(x.shape[0])), y=sig, name=name,\n",
    "                      mode=\"lines\", opacity=1))\n",
    "\n",
    "    fig.add_vline(x=len(x1), line_dash=\"dash\")\n",
    "    fig.update_xaxes(title_text=r'time')\n",
    "    fig.update_layout(title_text=f\"Sample {index}\",\n",
    "                      font_family=\"Serif\", font_size=14,\n",
    "                      margin_l=5, margin_t=50, margin_b=5, margin_r=5)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(dm.ds_std_train, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_data(ds, index, title=None):\n",
    "    x1, x2 = ds[index]\n",
    "    x = np.concatenate((x1, x2))\n",
    "\n",
    "    data = [go.Scatter(x=np.array(range(x.shape[0])), y=sig, name=name,\n",
    "                      mode=\"lines\", opacity=1) for sig, name in zip([x[:, 0], x[:, 1], x[:, 2]], ['h1', 'h2', 'h3'])]\n",
    "    layout = go.Layout(title_text=title,\n",
    "                       font_family=\"Serif\", font_size=14,\n",
    "                       margin_l=5, margin_t=50, margin_b=5, margin_r=5,\n",
    "                       xaxis_title=\"time\")\n",
    "    layout.shapes = [dict(type='line', x0=len(x1), x1=len(x1), y0=0, y1=1, yref='paper', xref='x', line=dict(dash='dash'))]\n",
    "\n",
    "    return data, layout\n",
    "\n",
    "def interactive_sample_plot(datamodule, sample_index=0):\n",
    "    datasets = datamodule.ds_dict\n",
    "    scenarios = datamodule.scenarios\n",
    "    def on_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            new_data, new_layout = plot_sample_data(datasets[dataset_dropdown.value], sample_dropdown.value, title=dataset_dropdown.value)\n",
    "            for i, trace in enumerate(new_data):\n",
    "                fig.data[i].update(trace)\n",
    "            fig.layout.update(new_layout)\n",
    "\n",
    "    dataset_dropdown = widgets.Dropdown(options=[\n",
    "                                            \"standard\",\n",
    "                                            \"fault\",\n",
    "                                            \"noise\",\n",
    "                                            \"duration\",\n",
    "                                            \"scale\",\n",
    "                                            \"switch\",\n",
    "                                            \"q1+v3\",\n",
    "                                            \"q1+v3+rest\",\n",
    "                                            \"v12+v23\"\n",
    "                                            ],\n",
    "                                            value=\"standard\",\n",
    "                                            description='Dataset:'\n",
    "                                        )\n",
    "    dataset_dropdown.observe(on_change)\n",
    "\n",
    "    max_sample_index = 99\n",
    "\n",
    "    sample_dropdown = widgets.Dropdown(options=list(range(max_sample_index + 1)),\n",
    "                                       value=sample_index,\n",
    "                                       description='Sample:')\n",
    "    sample_dropdown.observe(on_change)\n",
    "\n",
    "    data, layout = plot_sample_data(datasets[\"standard\"], sample_index, title=scenarios[0])\n",
    "    fig = go.FigureWidget(data=data, layout=layout)\n",
    "\n",
    "    display(widgets.VBox([dataset_dropdown, sample_dropdown, fig]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_sample_plot(dm)  # TODO copy from notebook 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42126a07",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee45754",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/processed/simulation_standard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data, sd=0.1):\n",
    "    data = data.copy()\n",
    "    data[\"h1\"] += np.random.normal(0, sd, len(data))\n",
    "    data[\"h2\"] += np.random.normal(0, sd, len(data))\n",
    "    data[\"h3\"] += np.random.normal(0, sd, len(data))\n",
    "    return data\n",
    "data_noisy = add_noise(data, 1)\n",
    "data_noisy.to_csv(\"data/processed/simulation_standard+.csv\", index=False)\n",
    "data_noisy2 = add_noise(data, 2)\n",
    "data_noisy2.to_csv(\"data/processed/simulation_standard++.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation(data_noisy.to_numpy()-data.to_numpy(), interval=[0, 5000], title='Added Noise', \n",
    "                # export_path='visualizations/simulation_standard+noise.pdf', \n",
    "                # height=400, width=800\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation(data_noisy2.to_numpy(), interval=[0, 5000], title='Standard Simulation with even more Added Noise', \n",
    "                # export_path='visualizations/simulation_standard+noise.pdf', \n",
    "                # height=400, width=800\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468516d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_frequency(df, std_dev=0.1):\n",
    "    # List of features\n",
    "    features = df.columns\n",
    "    \n",
    "    # Apply FFT to each feature\n",
    "    fft_df = df[features].apply(np.fft.fft)\n",
    "    \n",
    "    # Generate Gaussian noise for each feature\n",
    "    for feature in features:\n",
    "        noise = np.random.normal(0, std_dev, df.shape[0])\n",
    "        \n",
    "        # Apply noise in frequency domain\n",
    "        fft_df[feature] += noise\n",
    "\n",
    "    # Apply inverse FFT to return to time domain\n",
    "    augmented_df = fft_df.apply(np.fft.ifft)\n",
    "    \n",
    "    # Real part of complex number\n",
    "    augmented_df = augmented_df.apply(np.real)\n",
    "    \n",
    "    return augmented_df\n",
    "\n",
    "data_augmented = augment_frequency(data, std_dev=500)\n",
    "data_augmented.to_csv(\"data/processed/simulation_frequency.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9555586",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation(data_augmented.to_numpy()-data.to_numpy(), interval=[0, 5000], title='Augmented Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79992d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation(data_augmented.to_numpy(), interval=[0, 5000], title='Augmented Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5defd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_time_warp(df, warp_factor=0.2):\n",
    "    # Create a copy of the dataframe to avoid changing the original one\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Generate a random sequence of warp factors\n",
    "    warp = np.random.normal(loc=1.0, scale=warp_factor, size=len(df.index)-1)\n",
    "\n",
    "    # Adding 1 at the beginning of the warp array to maintain the original starting point\n",
    "    warp = np.insert(warp, 0, 1)\n",
    "    \n",
    "    # Cumulative sum of warp factors will be our new time index\n",
    "    time_index = np.cumsum(warp)\n",
    "    \n",
    "    # Normalize the new time index to match the range of the original index\n",
    "    time_index = np.interp(time_index, (time_index[0], time_index[-1]), (df.index[0], df.index[-1]))\n",
    "    \n",
    "    # Apply the interpolation function to the new time index for each feature\n",
    "    for feature in ['h1', 'h2', 'h3']:\n",
    "        interp_func = interp1d(df.index, df[feature].values, fill_value='extrapolate')\n",
    "        df_copy[feature] = interp_func(time_index)\n",
    "    \n",
    "    # Reset the index of the dataframe to match the original\n",
    "    df_copy.index = range(len(df))\n",
    "    \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warped = random_time_warp(data, warp_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06317d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.concat([data.iloc[-5000:], df_warped.iloc[-5000:]], axis=1)\n",
    "df0.columns = ['h1', 'h2', 'h3', 'h1_warped', 'h2_warped', 'h3_warped']\n",
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "fig = go.Figure()\n",
    "for col in df0.columns:\n",
    "    fig.add_trace(go.Scatter(x=df0.index, y=df0[col], name=col))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950793e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warped.to_csv(\"data/processed/simulation_time_warp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation(df_warped.to_numpy(), interval=None, title='Time Warped Data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e13bc41746ede79f3cfe704424fb4343b96315e8e9d484218a5a332a906daae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
